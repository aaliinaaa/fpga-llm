Основная цель - не реализация нейросетевой модели как таковой, а разработка отдельных функциональных компонент, из которых потом можно будет собирать конфигурацию. Т.е. сделать изначально упор на проектирование оптимизированной микроархитектуры.

**Разработка микроархитектуры и компонент модели**

Основной акцент сделан на аппаратной части проекта и проведении численных экспериментов; теоретическая часть по нейросетям и трансформерам будет выдана в формате as is.

**_Возможно перераспределение по времени внутри этапов (и, скорей всего так и будет), но должна сохраняться сама логика реализации проекта._**

## **Общая структура и этапы**

1. Подготовительный этап, настройка среды (1 неделя)
2. Проектирование микроархитектуры компонент Transformer (2 недели)
3. Реализация и верификация основных функциональных блоков (3 недели)
4. Интеграция блоков, отладка и функциональное тестирование (2 недели)
5. Оптимизация и синтез под ПЛИС (2 недели)
6. Проведение численных эксперименты, измерение производительности и ресурсозатрат (2 недели)
7. Доработка, итоговая проверка и подготовка отчётности (2 недели)

Общее время выполнения примерно 14 нед.

Ниже – детальные шаги по каждому этапу.

### **1. Подготовительный этап, настройка среды (1 неделя)**

1.1. Установка/настройка инструментов разработки

- Установка среды разработки Intel Quartus (актуальной версии для Cyclone V SoC).
- Настройка системных утилит и драйверов для платы с Cyclone V SoC.
- Чек инструкций и проверка на базовом примере

1.2. Определение структуры проекта и планирование репозитория

- Организация структуры проекта (папки для RTL-кода, тестбенчей, скриптов синтеза и т.д.).
- Настройка системы контроля версий (Git или аналог) т.к. делать будем все методично и правильно.

1.3. Конкретизация архитектурных требований к аппаратной реализации

- Определение целевых показателей: частота работы, объем потребляемых ресурсов (логика, память), пропускная способность, задержки.
- Составление списка конкретных блоков трансформера, которые планируется реализовать (Multi-Head Attention, Feed-Forward, Layer Norm, Softmax и пр.).
- Формулирование требований по объёму и формату данных (INT8, FP16, фиксированная точка и пр.).

**Ожидаемый результат этапа:**

- Рабочая среда, плата готовая для дальнейшей разработки.
- Есть структура проекта, сформирован список функциональных блоков для имплементации.
- Сформированное общее понимание как должны выглядеть компоненты.

### **2. Проектирование микроархитектуры компонент Transformer (2 недели)**

**2.1. Разработка блок-схемы будущего дизайна и определение интерфейсов. Один из наиболее критичных этапов, каждый компонент обсуждается детально.**

Распределение функций между FPGA и ARM. Проектирование структуры каждого компонента.
Модули вычислительного ядра, интерфейсы памяти, мосты HPS-FPGA.

FPGA:
- Токенизация?
- Модуль Multi-Head Attention (выделение логики для вычисления Q, K, V, софтмакс, матричные умножения и пр.)
- Feed-Forward слой.
- Layer Norm (включая оценку затрат ресурсов на деление, умножение, хранение статистик).
- Микрооперации: Add, Multiply, Accumulate, Shift, Activation и т.д.
- Определение входных/выходных интерфейсов между блоками (шины, сигналы синхронизации и управления).

ARM:
- загрузка/выгрузка данных, управление, возможно, предварительная/пост-обработка.

**2.2. Выбор подхода к описанию**

- Рассмотреть особенности использования DSP-блоков в Cyclone V, доступной внутренней памяти (Block RAM), а также влияния на скорость/ресурсы.

**2.3. Разработка спецификаций на уровне RTL**

- Спецификация ограничений по тактовой частоте и временных параметрах.
- Детализированное описание работы блоков, необходимых сигналов контроля/статуса.

**2.4. Выбор базового формата представления чисел для реализации (int8, fp16 и т.д.) 

- Создание эталонной модели: скрипты на торче или c++ конкретного блока с которой в итоге будет проводится сравнение.


**Ожидаемый результат этапа:**

- Сформированная архитектурная схема всех основных модулей и их взаимосвязей.
- Готовы предварительные спецификации RTL и список ресурсов, необходимых под каждый блок.

---

### **3. Реализация и верификация основных функциональных блоков (3 недели)**

3.1. Разработка RTL-кода для ключевых вычислительных модулей

-  Матричные умножения (например, для $Q_K^T$, $K_V$, и т.д.).
-  Softmax (может включать экспоненциальную аппроксимацию, деление на сумму).
-  Feed-Forward (обычно 2 линейных слоя с активацией ReLU/GeLU ).
-  Layer Normalization (вычисление средних и дисперсий).

3.2. Разработка тестбенчей (testbench) для каждого блока

- Написание тестов для проверки корректности операций
- Использование ModelSim или другого встроенного в Quartus инструмента для функциональной симуляции

3.3. Итеративная доработка на уровне RTL
- Исправление выявленных ошибок, оптимизация по логике, по количеству разрядов (фиксированная точка vs. плавающая точка).
- Добавление необходимых сигналов для отладки.

**Ожидаемый результат этапа:**

- Базовые функциональные блоки (аттеншн, feed-forward, softmax, layernorm) реализованы на RTL-уровне.
- Пройден первый набор тестов (модули корректно отрабатывают в симуляции).

---
### **4. Интеграция блоков, отладка и функциональное тестирование (2 недели)**

4.1. Интеграция блоков в единый дизайн

- Объединение отдельных модулей в топ-уровень.
- Определение управляющего автомата (или контроллера) для последовательного запуска компонент (Attention → Feed-Forward → и т.д.).
- Организация буферов (FIFO/BRAM) и прочей обвязки для передачи данных.

4.2. Функциональная симуляция на уровне системы

 - Создание системного тестбенча, подача на входы реалистичных тестовых векторов, проверка выходных данных.
 - Сравнение результатов с эталоном (например, результатом вычисления той же модели Transformer в pytorch реализации).

4.3. Отладка и устранение ошибок

- Уточнение задержек и проверка временных диаграмм.
- Корректировка архитектуры при необходимости (добавление конвейерных ступеней, изменение ширины шин и т.д.).

**Ожидаемый результат этапа:**

- Все основные модули объединены и функционируют совместно на уровне симуляции.
- Системный тест демонстрирует корректные результаты с учётом допусков фиксированной/плавающей точности.

---

## **5. Оптимизация и синтез под FPGA (2 недели)**

5.1. Первичный синтез проекта в Quartus

- Компиляция проекта под Cyclone V SoC.
- Оценка отчётов по использованию логики (ALM), DSP-блоков, памяти, максимальной частоты.

5.2. Оптимизация для повышения производительности и/или снижения ресурсов

- Добавление/исправление конвейерных ступеней.
- Переразводка ширины внутренних шин (уменьшение битности при сохранении достаточной точности).
- Использование встроенных DSP-блоков максимально эффективно (распараллеливание умножений и т.д.).

5.3. Повторный синтез и анализ

- Сравнение метрик (Fmax, использование ресурсов, потребление энергии).
- Оценка готовности к реальному тестированию на плате.

**Ожидаемый результат этапа:**

- Синтезируемый проект, удовлетворяет предварительным критериям (частично или полностью).
- Отчёты по загруженности чипа, времени задержек и рабочей частоте, а также план по дальнейшей доработке (если потребуются дополнительные улучшения).

---

## **6. Эксперименты, измерение производительности и ресурсозатрат (2 недели)**

6.1. Загрузка проекта на плату Cyclone V SoC

- Конфигурирование FPGA.
- Проверка работоспособности с реальными сигналами, отладка (использование встроенных LA-инструментов, если есть).

6.2. Измерение реальной производительности

- Измерение тактовой частоты, латентности обработки одного батча (или одного запроса).
- Замер потребляемой мощности (? при наличии соответствующих измерительных возможностей платы).
- Прогон данных в режиме стресс-тестов длительное время, контроль стабильности.

6.3. Сравнение с торч реализацией

- Сравнение полученных результатов (время обработки, точность результатов) с эталонным  скриптом на GPU.
- Анализ преимуществ и узких мест аппаратной реализации.

6.4. Сбор статистики для итоговой отчётности

- Формирование таблиц с показателями (Fmax, Latency, Throughput, Resource Utilization и т.д.).
- Сохранение логов и экспериментальных результатов.

**Ожидаемый результат этапа:**

- Подтверждение или корректировка заявленной производительности на реальном «железе».
- Подготовленные статистические данные и метрики эффективности реализации.

---

## **7. Доработка, итоговая проверка и подготовка отчётности (2 недели)**

7.1. Финальная оптимизация и исправления

- Устранение выявленных в ходе тестирования проблем (если есть сбои, некорректный вывод, несоответствие частоте и т.д.).
- Доп. оптимизация (при необходимости) в случае, если не достигнуты целевые показатели.

7.2. Итоговая проверка

- Повторное полное тестирование (симуляция, синтез, проверка на плате)/подтверждение стабильности инференса.

7.3. Подготовка финальной документации и презентации

- Оформление отчёта по проекту, включающего:
- Описание архитектуры. Схема общего пайплайна.
- Детали реализации (схемы, листинги основных модулей).
- Результаты измерений на FPGA (все метрики: производительность, ресурсы).
- Подготовка презентационных материалов (слайды, визуализации результатов численных экспериментов).

7.4. Резервное копирование и завершение (самый критически важный пункт)

- Бэкапы итоговых версий RTL-кода, битстримов, отчётов синтеза и т.д.

**Ожидаемый результат этапа:**

- Завершённый и протестированный проект, готовый к защите.
- Отчёт, презентация, экспериментальные данные.

---
## **Мотивация проекта**

Основная мотивация в имплементации архитектуры transformer – это подведение конечного устройства к задаче **_Referring Expression Generation (REG)_** или ему подобной.

Задача заключается в том, чтобы при наличии конкретного объекта (или региона) в видеопоследовательности сгенерировать текстовую фразу (описание)/_ИНСТРУКЦИЮ_, которая однозначно указывает на данный объект среди всех остальных объектов в сцене.

**Аналитический обзор и приложенные статьи:**

- Статьи где присутствует автор _Clément Farabet_ – достаточно старые, но имеет смысл изучить как были организованы первые работы по имплементации в железе первых нс, в том числе сверточные.

- Filip Roth _Using low cost FPGAs for realtime video processing_ – магистерская работа 2011 года по реализации нс на FPGA

- Также приложена магистерская работа 2017 года Американов А. А. из ВШЭ

_- High accuracy FPGA activation function implementation for neural networks_ – Статья про ипмелементацию функции активации

- Implementation of Massive Artificial Neural Networks with FPGA 2012 – Старая статья возможно что то есть полезное

_- FPGA-based Accelerators of Deep Learning Networks for Learning and Classification A Review –_ Статья обзор на различные работы по реализации, она достаточно старая, но тем не менее как вводная пойдет.

- _(1)Throughput optimizations for FPGA-based deep neural network inference –_ Способы оптимизации инференса нс на ПЛИС

_- FPGA Platform applied for Facial Expression Recognition System using Convolutional Neural Networks –_ распознавание выражения лица

_-_ _FPGA-__BASED_ _Hardware_ _Accelerators –_ книга или материалы лекций вообще про ускорение расчетов с помощью ПЛИС

_- 2012___Book___Guide_ _to_ _FPGA_ _Implementation_ _of_ _Arithmetic_ _Functions –_ Имплементация арифметических функций на ПЛИС, возможно будет полезно при работе над некоторыми компонентами

_- 2016_Book_High Performance Integer Arithmetic Circuit Design on FPGA_ – что то про целочисленные расчеты